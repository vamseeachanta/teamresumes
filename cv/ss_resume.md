---
margin-left: 2cm
margin-right: 2cm
margin-top: 1cm
margin-bottom: 2cm
title: Shaik Samdan , Software developer and Programmer
description-meta: 'Resume for job search'
keywords:
  - 'computer science engineer'
  - 'python'
author:
- Shaik Samdan
subject: 'resume_samdan'
---
##### <samdanshaik8998@gmail.com> |  +91-6302901157  | <https://github.com/samdansk2> | <https://www.linkedin.com/in/samdanshaik/>

### Software Engineer (Python) & Data Enthusiast Crafting AI-powered, automated solutions through code, data, and innovation

## Summary

- Multidisciplinary  software engineer with hands-on experience in Python programming, Data Science and Software Development.
- Strong background in developing Python-based tools for automating data analysis processes with a focus on engineering applications.
- Proficient in Python programming and familiar with various libraries and tools for data manipulation and analysis.
- Skilled in Web scraping processes using Scrapy with a strong understanding of data extraction techniques.
- Implemented CI/CD pipelines using GitHub Actions to automate testing and deployment for various 
projects.
- Passionate about writing clean, maintainable code and continuously learning new trends in technologies.
- Seeking a challenging role to further enhance my technical skills and contribute to innovative projects.
  
## Education

### 6 Years Integrated Course in Rajiv Gandhi University Of Knowledge Technologies, Srikakulam - AndhraPradesh , India

### Four - years B.Technology in Computer Science Engineering 

### Two - years Pre University Course(Board of Intermediate Education, AP)

## Skills

```engineering```
```python```
```data science```
```data visualization```
```artificial intelligence```
```programming```
```cs fundamentals```

**Python**: Functions , Classes , Methods , Dictionaries , Subprocess , Datetime , Lambda Function

**Data Science**: Regular expressions , numpy , pandas , Data Preprocessing , Data Visualization , DataFrames

**Web Scraping**: Data extraction , API interaction , Data Parsing , Webpage Inspection

**Tools**: Poetry , Scrapy , Beautiful Soup , Selenium , requests

**Web development**: Basic HTML , Javascript 

**Python libraries**: Matplotlib , Plotly , PIL , Sympy , Scikit-learn , yfinance , ffn

**Version Control**: Git, multiuser working, test driven development, test pipelines

**CI/CD**: GitHub Actions

**Test Driven Development**: OOPs, Unit Test, Integration Test

**Debugging**: IDE debugging, VS Code for all programming

**Programming Practices**: Algorithms, Data Structures , Configurations, Virtual environments (Conda)

**Yaml**: Pyyaml, Ruamel yaml

**Artificial Intelligence**: GitHub Copilot, ChatGPT

**Tech Tools**: Visual Studio Code (VS Code), Jupyter Notebook, Microsoft Office (Excel, PowerPoint, Word)

**Documentation**: Markdown, Plantuml flowcharts, Pyramid diagrams

**Databases**: MySQL, SQL Server


## Projects

### Template library for data science calculations

- Developed a simple python library for data science calculations using Python. (<https://github.com/samdansk2/librarytemplate>)
- Utilized branches to step through calculation phases
- Implemented a CI/CD pipeline using GitHub Actions to automate testing and deployment of the library.
- This application is benchmark for beginners as a good  start with public libraries and used for internal training of new members for the company.

### Web Scraper 

 - Built and optimized a Scrapy-based web scraper to automate the data extraction process from public websites.    
 - Enhanced the data processing pipeline by implementing data validation and transformation steps.
 - Leveraged Python's pandas to process and validate extracted data directly from HTTP responses.
 - Reduced the time required for data extraction and validation through automation, improving overall efficiency.
 - part of assetutilities (<https://github.com/vamseeachanta/assetutilities>) for automation of development processes.

### Oil and Gas Data Analysis (BSEE)

- The project's main aim is to focus on leveraging data analytics to enhance safety, environmental protection, and regulatory  oversight in offshore energy operations. 
- Analysis involves the following key components:
  - Data Extraction: Extracting useful data insights from the BSEE website using Scrapy. 
  - Data Analysis: Performing data analysis to identify production trends, patterns, and anomalies.
  - Data Visualization: Creating plots all kinds of data to present the analysis results effectively.
- Part of energydata (<https://github.com/vamseeachanta/energydata>) repository for data extraction and analysis from
  public sources.

### MES Files Analysis 

- Developed a Python-based tool to automate the analysis of warnings and errors from MES files.
- Implemented regular expressions to parse and extract warnings and errors.
- Generated a status table indicating the presence of warnings and errors in each file.
- Reduced the time required for MES file analysis , providing clear insights for project teams.

### Engineering Physics Based calculations

- Developed a module for cathodic protection and plate buckling calculations using Python.
- Part of digitalmodel (<https://github.com/vamseeachanta/digitalmodel>) repository for engineering physics based calculations.
- Calculated the cathodic protection for the following structures:
  - ships
  - subsea structures
  - pipelines


## Experience

### AceEngineer Inc., Houston TX, Remote

Python Developer (Full-time) | Sep 2024 - Present

- Library Template
  - Designed a template library for data science calculations using Python.

- Web Scraper
  - Implemented scrapy based tool for data extraction from BSEE website.

- Oil and Gas Data Analysis
  - Optimized data extraction and analysis processes for BSEE data.
  - Designed data visualization tools to present analysis results effectively.
  
- Automated Analysis Of MES Files
  - Formulated automation process to handle MES file warnings and errors across multiple projects.